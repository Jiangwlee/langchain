{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Message History\n",
    "\n",
    "`RunnableWithMessageHistory` 允许我们将消息历史记录添加到某些类型的链中，它包装另一个`Runnable`并管理它的消息历史记录。\n",
    "\n",
    "https://python.langchain.com/docs/expression_language/how_to/message_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're an assistant who's good at {ability}. Respond in 20 words or fewer\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "# 定义一个函数来获取历史消息\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Cosine is a trigonometric function that calculates the ratio of the adjacent side to the hypotenuse in a right triangle.', response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 33, 'total_tokens': 59}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a9fa9779-8218-494a-9b24-d9d5378dbd7c-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Cosine is a mathematical function used to calculate the ratio of the length of the adjacent side to the length of the hypotenuse in a right triangle.', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 69, 'total_tokens': 100}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-6172fe67-b628-41e4-81e3-6b1102a463c0-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remembers\n",
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"What?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='How can I assist you with math?', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 30, 'total_tokens': 38}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ee6cd1db-47c6-4e42-a55e-5d8f11cbef93-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New session_id --> does not remember.\n",
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"What?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"def234\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义历史消息记录的配置参数\n",
    "\n",
    "下面使用 `user_id` 和 `conversation_id` 作为主键，定义历史消息记录的配置参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
    "    if (user_id, conversation_id) not in store:\n",
    "        store[(user_id, conversation_id)] = ChatMessageHistory()\n",
    "    return store[(user_id, conversation_id)]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    "    history_factory_config=[\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",\n",
    "            annotation=str,\n",
    "            name=\"Conversation ID\",\n",
    "            description=\"Unique identifier for the conversation.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='乘法分配律是指 a × (b + c) = a × b + a × c，其中 a、b、c 是任意实数。', response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 59, 'total_tokens': 96}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a5c7a6ad-0a32-4183-a9af-bb8311deaef9-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"什么是乘法分配律\"},\n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='乘法分配律是一个数学原理，它说明了如何在进行乘法运算时，将一个数与括号内的两个数相加后再相乘。', response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 105, 'total_tokens': 154}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e9a095ab-afdb-4440-a906-dce1b3425772-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"What\"},\n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Do you need help with a math problem?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 29, 'total_tokens': 38}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d1020eb4-4e67-4b72-937e-1aef597e153d-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用不同的 conversation_id 无法定位到历史消息，因此这次对话不受历史消息的影响\n",
    "\n",
    "with_message_history.invoke(\n",
    "    {\"ability\": \"math\", \"input\": \"What\"},\n",
    "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"2\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples with runnables of different signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_message': AIMessage(content='Simone de Beauvoir believed in the existence of free will. She argued that individuals have the ability to make choices and act upon them, rather than being determined by external circumstances or societal expectations. Beauvoir emphasized the importance of personal responsibility and the need for individuals to actively engage in the world and create their own meaning and purpose. In her book \"The Ethics of Ambiguity,\" she wrote, \"Man is condemned to be free; because once thrown into the world, he is responsible for everything he does.\" Beauvoir rejected any deterministic or fatalistic views that deny human agency and advocated for the exercise of free will in order to achieve personal and collective liberation.', response_metadata={'token_usage': {'completion_tokens': 133, 'prompt_tokens': 17, 'total_tokens': 150}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f546c036-9b8b-4d8d-b4c7-42c8ec28ce79-0')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "chain = RunnableParallel({\"output_message\": ChatOpenAI()})\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    output_messages_key=\"output_message\",\n",
    ")\n",
    "\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What did Simone de Beauvoir believe about free will\")],\n",
    "    config={\"configurable\": {\"session_id\": \"baz\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_message': AIMessage(content='Simone de Beauvoir\\'s views on free will closely align with those of Jean-Paul Sartre, her longtime partner and philosophical collaborator. Both Beauvoir and Sartre were existentialists who emphasized human freedom and the ability to make choices. They rejected any notion of determinism or predestination and believed that individuals are responsible for their actions and the meaning they give to their lives.\\n\\nSartre famously stated in his book \"Being and Nothingness\" that \"Man is condemned to be free,\" echoing Beauvoir\\'s perspective. He argued that human existence precedes essence, meaning that individuals are first thrown into the world without predetermined purposes or meanings. According to Sartre, individuals have the freedom to define their own essence through their actions and choices.\\n\\nWhile Beauvoir and Sartre shared similar views on free will, they did have some differences in their philosophical perspectives. For example, Beauvoir emphasized the importance of understanding the social and cultural context in which individuals make their choices, particularly in relation to gender and women\\'s liberation. She argued that societal expectations and structures can limit individuals\\' freedom and called for the dismantling of such oppressive systems.\\n\\nOverall, Beauvoir and Sartre were united in their belief in free will and the responsibility individuals have in creating their own meaning and purpose in life. However, Beauvoir\\'s feminist perspective and focus on social and political liberation added unique dimensions to their shared existentialist philosophy.', response_metadata={'token_usage': {'completion_tokens': 287, 'prompt_tokens': 166, 'total_tokens': 453}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-90be171c-cc34-412b-9e74-7313ec316923-0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"How did this compare to Sartre\")],\n",
    "    config={\"configurable\": {\"session_id\": \"baz\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000014AFFDDC290>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000014AFFDDC800>, openai_api_key=SecretStr('**********'), openai_api_base='https://api.chatanywhere.tech/v1', openai_proxy=''), config_factories=[<function Runnable.with_listeners.<locals>.<lambda> at 0x0000014AFFE2CAE0>]), config={'run_name': 'RunnableWithMessageHistory'}), get_session_history=<function get_session_history at 0x0000014AE32DD9E0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Message input, message output\n",
    "\n",
    "RunnableWithMessageHistory(\n",
    "    ChatOpenAI(),\n",
    "    get_session_history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  input_messages: RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
       "}), config={'run_name': 'insert_history'})\n",
       "| RunnableBinding(bound=RunnableLambda(itemgetter('input_messages'))\n",
       "  | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000014AFFDDC0B0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000014AFFE40500>, openai_api_key=SecretStr('**********'), openai_api_base='https://api.chatanywhere.tech/v1', openai_proxy=''), config_factories=[<function Runnable.with_listeners.<locals>.<lambda> at 0x0000014AFFE2ED40>]), config={'run_name': 'RunnableWithMessageHistory'}), get_session_history=<function get_session_history at 0x0000014AE32DD9E0>, input_messages_key='input_messages', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dict with single key for all messages input, messages output\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "RunnableWithMessageHistory(\n",
    "    itemgetter(\"input_messages\") | ChatOpenAI(),\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input_messages\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
